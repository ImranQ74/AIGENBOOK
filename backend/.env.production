# AIGENBOOK Production Environment Variables
# Copy this to .env on your deployment platform

# ===========================================
# Server Configuration
# ===========================================
HOST=0.0.0.0
PORT=8000
DEBUG=false

# ===========================================
# LLM Configuration (REQUIRED)
# ===========================================
# Recommended: Use Groq for fast free-tier inference
# Sign up at https://console.groq.com
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo
LLM_API_BASE=https://api.groq.com/openai/v1
LLM_API_KEY=gsk_...  # YOUR GROQ API KEY HERE

# ===========================================
# Qdrant Vector Database (OPTIONAL)
# ===========================================
# For production with data persistence
# Sign up at https://cloud.qdrant.io
# QDRANT_URL=https://xxx-xxx.aws.cloud.qdrant.io
# QDRANT_API_KEY=...
QDRANT_COLLECTION_NAME=aigenbook_chunks

# ===========================================
# Neon PostgreSQL (OPTIONAL)
# ===========================================
# For persistent user preferences
# Sign up at https://neon.tech
# NEON_DATABASE_URL=postgresql://user:pass@host/db

# ===========================================
# Embedding Model
# ===========================================
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu

# ===========================================
# RAG Configuration
# ===========================================
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K=5
